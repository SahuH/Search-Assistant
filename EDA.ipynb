{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380f2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec151aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/airbnb_properties.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6714d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Python: Find city name from latitude and longitude\n",
    "from geopy.geocoders import Nominatim, GeoNames\n",
    "geolocator = Nominatim(user_agent=\"myapplication\")\n",
    "def findCity(lat, lon):\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), exactly_one=True)\n",
    "        address = location.raw['address']\n",
    "        city = address.get('city', '')\n",
    "        if city == '':\n",
    "            city = address.get('state', '')\n",
    "        if city == '':\n",
    "            city = address.get('country', '')\n",
    "        return city\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "df[\"city\"] = df.apply(lambda row: findCity(row['latitude'], row['longitude']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75a599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row = df.sample(1) \n",
    "# lat, lon = row['latitude'].values[0], row['longitude'].values[0]\n",
    "# location = geolocator.reverse((lat, lon), exactly_one=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3912dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dccc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6debfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import chromadb\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Load synonym mapping\n",
    "with open(\"./data/metadata_searchDB.json\", \"r\") as f:\n",
    "    synonym_mapping = json.load(f)\n",
    "\n",
    "# Reverse mapping for quick lookup\n",
    "synonym_to_attribute = {}\n",
    "for attribute, synonyms in synonym_mapping.items():\n",
    "    for s in synonyms:\n",
    "        synonym_to_attribute[s.lower()] = attribute\n",
    "\n",
    "# # Instantiate the LLM (replace model with any open-source instruct model)\n",
    "# # You can also use: \"HuggingFaceH4/zephyr-7b-beta\" or similar\n",
    "# llm = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=\"sshleifer/tiny-gpt2\",\n",
    "#     max_new_tokens=512,\n",
    "#     temperature=0.2,\n",
    "#     do_sample=True\n",
    "# )\n",
    "\n",
    "# Prompt template\n",
    "def generate_prompt(user_query: str):\n",
    "    return f\"\"\"\n",
    "You are a helpful assistant. A user has provided the following query:\n",
    "\n",
    "\"{user_query}\"\n",
    "\n",
    "Your task is to extract structured filters from this query. Use the list of metadata attributes and their common synonyms to determine the attribute being referenced.\n",
    "\n",
    "Use the following output format:\n",
    "[\n",
    "  {{\n",
    "    \"attribute\": \"guests\",\n",
    "    \"condition\": \">=\",\n",
    "    \"value\": 3\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "Only include attributes from this list: {list(synonym_mapping.keys())}\n",
    "Make sure to infer:\n",
    "- Condition (>=, <=, ==, includes)\n",
    "- Value (numerical or list of strings)\n",
    "- Use JSON format only.\n",
    "\"\"\"\n",
    "\n",
    "# Function to parse model output\n",
    "def llm_metadata_extraction(user_query):\n",
    "    prompt = generate_prompt(user_query)\n",
    "    result = llm(prompt)[0][\"generated_text\"]\n",
    "\n",
    "    # Extract the first valid JSON array from the output\n",
    "    try:\n",
    "        json_text = re.findall(r\"\\[\\s*{.*?}\\s*]\", result, re.DOTALL)[0]\n",
    "        return json.loads(json_text)\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing response:\", e)\n",
    "        print(\"Raw model output:\", result)\n",
    "        return []\n",
    "\n",
    "# # Example function (mocking actual LLM usage)\n",
    "# def llm_metadata_extraction(query: str):\n",
    "#     return [\n",
    "#         {\"attribute\": \"guests\", \"condition\": \">=\", \"value\": 3},\n",
    "#         {\"attribute\": \"bedrooms\", \"condition\": \">=\", \"value\": 2},\n",
    "#         {\"attribute\": \"ttm_avg_rate\", \"condition\": \"<=\", \"value\": 1000},\n",
    "#         {\"attribute\": \"amenities\", \"condition\": \"includes\", \"value\": [\"pool\", \"gym\"]}\n",
    "#     ]\n",
    "\n",
    "# # Metadata filtering using ChromaDB\n",
    "# def retrieve_with_metadata_filtering(query: str):\n",
    "#     filters = llm_metadata_extraction(query)\n",
    "\n",
    "#     DB_URI = \"postgresql://admin:admin@localhost:5432/airbnbdb\"\n",
    "#     TABLE_NAME = \"airbnb_properties\"\n",
    "#     CHROMA_DIR = \"../data/chroma_store\"\n",
    "#     COLLECTION_NAME = \"airbnb_properties\"\n",
    "\n",
    "#     chroma_client = chromadb.PersistentClient(path=CHROMA_DIR)\n",
    "#     collection = chroma_client.get_or_create_collection(COLLECTION_NAME)\n",
    "\n",
    "#     exact_filters = {}\n",
    "#     for f in filters:\n",
    "#         if f[\"condition\"] == \"==\":\n",
    "#             exact_filters[f[\"attribute\"]] = f[\"value\"]\n",
    "#         elif f[\"condition\"] == \"includes\":\n",
    "#             for val in f[\"value\"]:\n",
    "#                 exact_filters[f\"{f['attribute']}_{val}\"] = True\n",
    "\n",
    "#     results = collection.query(\n",
    "#         query_texts=[query],\n",
    "#         n_results=10,\n",
    "#         where=exact_filters\n",
    "#     )\n",
    "#     return results\n",
    "\n",
    "# # Test it\n",
    "# query = \"Looking for a 3-bedroom place that can accommodate at least 6 guests, with 2 bathrooms.\"\n",
    "# results = retrieve_with_metadata_filtering(query)\n",
    "\n",
    "# print(results)\n",
    "\n",
    "# query = \"Looking for a 3-bedroom place that can accommodate at least 6 guests, with 2 bathrooms.\"\n",
    "# filters = llm_metadata_extraction(query)\n",
    "# print(json.dumps(filters, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = pipeline(\n",
    "#     \"text2text-generation\",\n",
    "#     model=\"google/flan-t5-small\",\n",
    "#     max_new_tokens=512,\n",
    "#     temperature=0.2,\n",
    "#     do_sample=True\n",
    "# )\n",
    "\n",
    "\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "# client = InferenceClient(\n",
    "#     model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "#     token=\"\"\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "client = InferenceClient()\n",
    "\n",
    "query = \"Looking for a 3-bedroom place that can accommodate at least 6 guests, with 2 bathrooms.\"\n",
    "prompt = generate_prompt(query)\n",
    "response = client.text_generation(\n",
    "    prompt=prompt,\n",
    "    max_new_tokens=150\n",
    ")\n",
    "\n",
    "# response = client.conversational(\n",
    "#         messages=[\n",
    "#         {\"role\": \"user\", \"content\": prompt}\n",
    "#     ]\n",
    "#     max_tokens=256,\n",
    "# )\n",
    "\n",
    "# output = client.chat.completions.create(\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Count to 10\"},\n",
    "#     ],\n",
    "#     stream=True,\n",
    "#     max_tokens=1024,\n",
    "# )\n",
    "\n",
    "\n",
    "print(response)\n",
    "\n",
    "# prompt = generate_prompt(query)\n",
    "# result = llm(prompt)[0][\"generated_text\"]\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ce8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92378611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 404\n",
      "Raw Response Text: Not Found\n",
      "Failed to decode JSON: Expecting value: line 1 column 1 (char 0)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "# headers = {\n",
    "#     \"Authorization\": f\"Bearer\"\n",
    "# }\n",
    "\n",
    "\n",
    "# user_query = \"Looking for a 3-bedroom place that can accommodate at least 6 guests, with 2 bathrooms.\"\n",
    "\n",
    "# # Example conversation\n",
    "# payload = {\n",
    "#     \"inputs\": {\n",
    "#         \"past_user_inputs\": [],\n",
    "#         \"generated_responses\": [],\n",
    "#         \"text\": prompt\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "# def query(payload):\n",
    "#     response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "#     print(f\"Status Code: {response.status_code}\")\n",
    "#     print(\"Raw Response Text:\", response.text)\n",
    "\n",
    "#     try:\n",
    "#         return response.json()\n",
    "#     except Exception as e:\n",
    "#         print(\"Failed to decode JSON:\", str(e))\n",
    "#         return None\n",
    "\n",
    "\n",
    "# output = query(payload)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c96ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6bd6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
